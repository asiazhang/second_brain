# 数据一致性问题

之前没怎么参与过数据项目，因此对数据一致性问题不太理解。后来加入阿基米德数据中台项目，发现对于这种项目，数据一致性是个大问题。

简单描述一下项目背景：阿基米德数据平台通过采集代码仓库的commits/MergeRequests信息，对其进行分析，然后进行数据建模，生成统计数据给用户展示。

遇到的问题如下：

1. 采集的commits/merge_requesets/reviews数据缺失。
2. 采集的E2E追溯信息存在，但是依赖的commits信息不存在
3. 用户仓库改名后导致统计数据出错
4. 重复多余数据
5. ...

结果就是被用户投诉，说我们数据不准。根据分析，我总结出解决数据一致性问题的几种典型问题。

## 业务规则导致的数据不一致
之前做仓库数据采集的规则是根据用户git仓库地址来判断的，这样存在问题：
1. 用户在gitlab上修改仓库名字，则会被认为是一个新仓库
	> 比如从`git.huawei.com/devops/bk1.git`修改为`git.huawei.com/devops-data/background.git`，后者被认为是一个新仓库
2. 用户使用不同域名访问一个仓库，会认为是2个仓库
	> 将代码库访问地址从`git.huawei.com/devops/bk1.git`替换为`codehub-g.huawei.com/devops/bk1.git`，而`git.huawei.com`与`codehub-g.huawei.com`只是界面风格不同，后台数据完全一致

由于之前的业务规则错误的使用git仓库地址作为主键，导致后续维护中的各种问题。

## 程序问题导致数据不一致
程序开发中的BUG也有可能导致数据不一致。

### 没有采用事务
之前代码解析逻辑：

1. 调用`mirrorRepository.log`解析当前commit`c1`
2. 查询数据库是否存在`c1`，正常情况应该是没有
3. 将c1数据写入数据库
4. 开始解析c1的提交详情（分析commit里面的具体文件变更）
5. 解析完成后，保存超大提交信息`e1`
6. 解析完成后，保存commit变更详情`d1`
7. 解析完成后，调用updateNodeLoc更新`c1`的代码行增删改数目

这里的逻辑中，分别有四次数据库入库操作：
1. commit解析结果`c1`入库
2. 超大提交`e1`入库
3. commit变更详情`d1`入库
4. 更新数据库`c1`

从数据依赖来看，c1最终结果依赖于d1，e1依赖于c1，如果中间处理出现异常，可能导致c1数据不完整。

### 并发写入时序问题
当前我们是根据Webhook事件来更新MergeRequest数据。这里可能存在一些问题，针对同一个MR，git仓库发送了`W1`/`W2`/`W3`三个事件，但是这三个事件在消费端的处理顺序可能不一致，可能的更新顺序为：`W2`/`W3`/`W1`，导致最后的MR状态不正确。

这种需要保证消息处理时序的数据，要特殊处理。

> 我们在项目中的处理就是只使用事件的MR ID，然后通过这个ID来调用API查询MR数据，这样无论事件顺序如何，实际执行逻辑都一致。

## 数据库模型问题导致数据不一致

模型上没有外键和唯一约束，可能导致：

1. 数据重复，已经有用户投诉说检视意见重复了
2. 孤立数据，比如误删除了某个仓库的MR，但是MR关联的数据还在

> 模型上最好的方式就是加上唯一索引和[[外键约束]]。